{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd32ca6",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Examples: Association\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we will explore the fundamentals of association rule learning and the Apriori algorithm, including their definitions, steps, and practical applications in data mining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "- Understand the concept and significance of association rules in data mining.\n",
    "- Learn the steps and mechanics of the Apriori algorithm for finding frequent item sets.\n",
    "- Apply the Apriori algorithm using Python to uncover patterns in transactional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706055d0",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Association rule learning is a critical data mining method used to **uncover interesting relationships among variables within large datasets**. This technique is particularly effective in **market basket analysis**, where it aims to find sets of products that frequently co-occur in transactions. For instance, understanding that customers who buy bread often buy butter can help businesses improve product placement, enhance cross-selling strategies, and optimise inventory management.\n",
    "\n",
    "The Apriori algorithm is one of the most well-known algorithms for **mining frequent item sets and generating association rules**. It operates on the principle that if an item set is frequent, then all of its subsets must also be frequent. This property, known as the **Apriori property**, helps reduce the computational complexity involved in discovering frequent item sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68420e",
   "metadata": {},
   "source": [
    "## Association rule\n",
    "\n",
    "### Definition\n",
    "\n",
    "Association rules are used to identify relationships among a set of items in transactional data. Each rule is represented in the form of X → Y, where \\( X \\) is the antecedent (left-hand side) and \\( Y \\) is the consequent (right-hand side). The antecedent is a set of items found in the transaction data, and the consequent is another set of items that often occur with the antecedent.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider a retail scenario where we have transactional data of customer purchases. An example of an association rule could be:\n",
    "- **Rule:** {milk, bread} → {butter}\n",
    "- **Interpretation:** If a customer buys milk and bread, they are likely to also buy butter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d9f32",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "To evaluate the strength of an association rule, we use several metrics:\n",
    "\n",
    "- **Support:** This measures how frequently the item set appears in the dataset. For an item set \\(X\\), support is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Support}(X) = \\frac{\\text{Number of transactions containing } X}{\\text{Total number of transactions}}\n",
    "$$\n",
    "\n",
    "\n",
    "- **Confidence:** This measures how often the items in \\(Y\\) appear in transactions that contain \\(X\\). For a rule X → Y, confidence is defined as:\n",
    "  \n",
    "$$\n",
    "\\text{Confidence}(X \\rightarrow Y) = \\frac{\\text{Support}(X \\cup Y)}{\\text{Support}(X)}\n",
    "$$\n",
    "\n",
    "\n",
    "- **Lift:** This measures the ratio of the observed support to that expected if \\(X\\) and \\(Y\\) were independent. For a rule X → Y, lift is defined as:\n",
    "  \n",
    "$$\n",
    "\\text{Lift}(X \\rightarrow Y) = \\frac{\\text{Support}(X \\cup Y)}{\\text{Support}(X) \\times \\text{Support}(Y)}\n",
    "$$\n",
    "\n",
    "\n",
    "Higher values of support, confidence, and lift indicate stronger associations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a6d71",
   "metadata": {},
   "source": [
    "## Apriori algorithm\n",
    "\n",
    "### Definition\n",
    "\n",
    "The Apriori algorithm is a fundamental algorithm used to find frequent item sets and generate association rules. It uses a breadth-first search strategy and applies a principle known as the \"Apriori property.\" This property states that if an item set is frequent, then all of its non-empty subsets must also be frequent.\n",
    "\n",
    "### Steps\n",
    "\n",
    "The Apriori algorithm consists of the following steps:\n",
    "\n",
    "1. **Generate candidate item sets:** Generate all possible item sets of a given length from the dataset.\n",
    "2. **Prune:** Remove item sets that do not meet the minimum support threshold. This step reduces the number of candidate item sets to consider.\n",
    "3. **Repeat:** Increase the length of item sets by one and repeat the process of generating and pruning until no more frequent item sets are found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990cbe7",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "To better understand the Apriori algorithm, let's go through a detailed example. \n",
    "\n",
    "**Dataset:**\n",
    "Imagine we have the following transactions in a supermarket:\n",
    "\n",
    "```\n",
    "T1: {milk, bread, butter}\n",
    "T2: {beer, bread}\n",
    "T3: {milk, bread, butter, beer}\n",
    "T4: {bread, butter}\n",
    "T5: {milk, bread, beer}\n",
    "```\n",
    "\n",
    "Here's how we can implement the Apriori algorithm step-by-step:\n",
    "\n",
    "**Step 1: Generate candidate item_sets of length 1**\n",
    "- This means we look at all the individual items in the transactions and count their occurrences.\n",
    "- Candidate item_sets of length 1: {milk}, {bread}, {butter}, {beer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7977baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate item sets of Length 1:\n",
      "milk: 3\n",
      "bread: 5\n",
      "butter: 3\n",
      "beer: 3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Sample dataset\n",
    "transactions = [\n",
    "    ['milk', 'bread', 'butter'],\n",
    "    ['beer', 'bread'],\n",
    "    ['milk', 'bread', 'butter', 'beer'],\n",
    "    ['bread', 'butter'],\n",
    "    ['milk', 'bread', 'beer']\n",
    "]\n",
    "\n",
    "# Step 1: Generate candidate item_sets of length 1\n",
    "items = Counter(item for transaction in transactions for item in transaction)\n",
    "\n",
    "# items_list = []\n",
    "# for transaction in transactions:\n",
    "#     for item in transaction:\n",
    "#         items_list.append(item)\n",
    "        \n",
    "print(\"Candidate item sets of Length 1:\")\n",
    "for item, count in items.items():\n",
    "    print(f\"{item}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9a826",
   "metadata": {},
   "source": [
    "**Step 2: Prune Non-Frequent item sets**\n",
    "- Set a minimum support threshold (e.g., 0.6) and prune item sets that do not meet this threshold.\n",
    "- Minimum support threshold = 3 (since we have 5 transactions, 0.6 * 5 = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083a9c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent item sets of length 1:\n",
      "milk: 3\n",
      "bread: 5\n",
      "butter: 3\n",
      "beer: 3\n"
     ]
    }
   ],
   "source": [
    "# Minimum support threshold\n",
    "min_support = 3\n",
    "\n",
    "# Pruning step\n",
    "frequent_items = {item: count for item, count in items.items() if count >= min_support}\n",
    "print(\"Frequent item sets of length 1:\")\n",
    "for item, count in frequent_items.items():\n",
    "    print(f\"{item}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7504a0",
   "metadata": {},
   "source": [
    "**Step 3: Generate Candidate item sets of Length 2**\n",
    "- Combine frequent item sets of length 1 to generate item sets of length 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81cab3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate item sets of length 2:\n",
      "('milk', 'bread')\n",
      "('milk', 'butter')\n",
      "('milk', 'beer')\n",
      "('bread', 'butter')\n",
      "('bread', 'beer')\n",
      "('butter', 'beer')\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Generate candidate item sets of length 2\n",
    "candidate_item_sets_2 = list(combinations(frequent_items, 2))\n",
    "print(\"Candidate item sets of length 2:\")\n",
    "for item_set in candidate_item_sets_2:\n",
    "    print(item_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135ce2d",
   "metadata": {},
   "source": [
    "**Step 4: Prune Non-Frequent item sets of Length 2**\n",
    "- Count the occurrences of each item set in the transactions and prune those that do not meet the minimum support threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da524fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent item sets of length 2:\n",
      "('milk', 'bread'): 3\n",
      "('bread', 'butter'): 3\n",
      "('bread', 'beer'): 3\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each candidate item set in the transactions\n",
    "item_set_counts_2 = Counter()\n",
    "for transaction in transactions:\n",
    "    for item_set in candidate_item_sets_2:\n",
    "        if all(item in transaction for item in item_set):\n",
    "            item_set_counts_2[item_set] += 1\n",
    "\n",
    "# Pruning step\n",
    "frequent_item_sets_2 = {item_set: count for item_set, count in item_set_counts_2.items() if count >= min_support}\n",
    "print(\"Frequent item sets of length 2:\")\n",
    "for item_set, count in frequent_item_sets_2.items():\n",
    "    print(f\"{item_set}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac22fd5",
   "metadata": {},
   "source": [
    "**Step 5: Generate Candidate item sets of Length 3**\n",
    "- Combine frequent item sets of length 2 to generate item sets of length 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107f225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate item sets of length 3:\n",
      "('beer', 'bread', 'milk')\n",
      "('bread', 'butter', 'milk')\n",
      "('beer', 'bread', 'butter')\n"
     ]
    }
   ],
   "source": [
    "# Generate candidate item sets of length 3\n",
    "candidate_item_sets_3 = [tuple(sorted(set(a) | set(b))) for a in frequent_item_sets_2 for b in frequent_item_sets_2 if len(set(a) | set(b)) == 3]\n",
    "candidate_item_sets_3 = list(set(candidate_item_sets_3))  # Remove duplicates\n",
    "print(\"Candidate item sets of length 3:\")\n",
    "for item_set in candidate_item_sets_3:\n",
    "    print(item_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf54f7",
   "metadata": {},
   "source": [
    "**Step 6: Prune Non-Frequent item sets of Length 3**\n",
    "- Count the occurrences of each item set in the transactions and prune those that do not meet the minimum support threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0623746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent item sets of length 3:\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each candidate item set in the transactions\n",
    "item_set_counts_3 = Counter()\n",
    "for transaction in transactions:\n",
    "    for item_set in candidate_item_sets_3:\n",
    "        if all(item in transaction for item in item_set):\n",
    "            item_set_counts_3[item_set] += 1\n",
    "\n",
    "# Pruning step\n",
    "frequent_item_sets_3 = {item_set: count for item_set, count in item_set_counts_3.items() if count >= min_support}\n",
    "print(\"Frequent item sets of length 3:\")\n",
    "for item_set, count in frequent_item_sets_3.items():\n",
    "    print(f\"{item_set}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b34a4",
   "metadata": {},
   "source": [
    "Since no more frequent item sets can be generated, the algorithm stops here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97baa52",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "Here’s a practical implementation of the Apriori algorithm using Python with the `apyori` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89ae5d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apyori\n",
      "  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: apyori\n",
      "  Building wheel for apyori (setup.py): started\n",
      "  Building wheel for apyori (setup.py): finished with status 'done'\n",
      "  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5976 sha256=b898761df256d4aa0e6c5701ac425152d4363bfabaa53948ee7cfe93551c452f\n",
      "  Stored in directory: c:\\users\\tcala\\appdata\\local\\pip\\cache\\wheels\\7f\\49\\e3\\42c73b19a264de37129fadaa0c52f26cf50e87de08fb9804af\n",
      "Successfully built apyori\n",
      "Installing collected packages: apyori\n",
      "Successfully installed apyori-1.1.2\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below to install the required library\n",
    "!pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8dcad98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final set: ['bread', 'beer', 'milk']\n",
      "Support: 0.4\n",
      "Confidence: 0.8\n",
      "Lift: 1.3333333333333335\n",
      "Potential Apriori Rule:  ['bread', 'milk']   ->  ['beer']\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "# Import the required modules\n",
    "from apyori import apriori\n",
    "\n",
    "# Sample dataset\n",
    "transactions = [\n",
    "    ['milk', 'bread', 'butter'],\n",
    "    ['beer', 'bread', 'butter'],\n",
    "    ['milk', 'bread', 'butter', 'beer'],\n",
    "    ['bread', 'butter'],\n",
    "    ['milk', 'bread', 'beer'],\n",
    "    ['milk', 'butter'],\n",
    "    ['bread', 'butter', 'beer'],\n",
    "    ['milk', 'bread', 'butter', 'beer'],\n",
    "    ['bread', 'butter'],\n",
    "    ['milk', 'bread', 'beer']\n",
    "]\n",
    "\n",
    "# Applying Apriori \n",
    "rules = apriori(transactions, min_support=0.3, min_confidence=0.8, min_lift=1.2)\n",
    "\n",
    "# Collecting results and converting them into a list\n",
    "results = list(rules)\n",
    "\n",
    "# Filtering results to include only those with a minimum length of 2\n",
    "filtered_results = [result for result in results if len(result.items) >= 2]\n",
    "\n",
    "# Displaying results\n",
    "if not filtered_results:\n",
    "    print(\"No rules found with the specified criteria.\")\n",
    "else:\n",
    "    for result in filtered_results:\n",
    "        # Print the items in the rule\n",
    "        print(f\"Final set: {list(result.items)}\")\n",
    "        \n",
    "        # Print the support of the rule\n",
    "        print(f\"Support: {result.support}\")\n",
    "        \n",
    "        # Print the confidence and lift of the rule\n",
    "        for stat in result.ordered_statistics:\n",
    "            print(f\"Confidence: {stat.confidence}\")\n",
    "            print(f\"Lift: {stat.lift}\")\n",
    "            items_base1 = stat.items_base\n",
    "            items_add1 = stat.items_add\n",
    "            print('Potential Apriori Rule: ', list(items_base1), '  -> ', list(items_add1))\n",
    "        \n",
    "        print(\"====================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60fcf4e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Apriori algorithm plays a crucial role in data mining for discovering frequent item sets and generating association rules. It leverages the Apriori property to efficiently prune the search space, making it feasible to mine large datasets. This algorithm is widely used in various applications, such as market basket analysis, to uncover significant associations and patterns that can inform strategic decisions.\n",
    "\n",
    "Understanding and implementing the Apriori algorithm equips data scientists with a powerful tool for uncovering hidden patterns in transactional data, ultimately driving better business insights and decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
