{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee-v8I_P8rfp"
   },
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Exercise.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>\n",
    "\n",
    "# Exercise: Principal component analysis\n",
    "© ExploreAI Academy\n",
    "\n",
    "In this exercise, we apply PCA to a dataset, evaluate the cumulative variance explained, and determine the appropriate number of components to retain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ITqrvAqq8xSC"
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "* Apply PCA to reduce a dataset’s dimensionality.\n",
    "* Evaluate the cumulative variance explained by each principal component.\n",
    "* Determine the number of components needed to capture at least 85% of the variance. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Digits dataset consists of 1,797 images of handwritten digits, each represented by a 64-dimensional feature vector. The dataset's high dimensionality can pose challenges when visualising and exploring it and could also lead to model complexity.\n",
    "\n",
    "In this exercise, we apply PCA to the Digits dataset and evaluate its ability to reduce the dataset's dimensionality while retaining valuable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "To reduce the dataset's dimensionality, let's transform the standardised dataset by applying PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here...\n",
    "\n",
    "pca = PCA()\n",
    "pca_data = pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "To understand which components carry the most information, we can assess how much of the dataset's variance is captured by each principal component.\n",
    "\n",
    "Compute and print the `Explained Variance Ratio` for each principal component formatted to four decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here...\n",
    "\n",
    "for poc in pca.explained_variance_ratio_:\n",
    "    print(round(poc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "We can also evaluate how much total variance is captured as components are added incrementally. This can help us get a view of how many components are needed to capture a substantial proportion of the dataset's variance.\n",
    "\n",
    "Determine the cumulative variance ratio by summing the explained variance ratios of each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12033916, 0.21594971, 0.30039385, 0.36537793, 0.41397948,\n",
       "       0.45612068, 0.49554151, 0.52943532, 0.55941753, 0.58873755,\n",
       "       0.61655561, 0.64232616, 0.66507919, 0.68735099, 0.70900328,\n",
       "       0.72814495, 0.74590042, 0.76228111, 0.77824572, 0.79313763,\n",
       "       0.80661732, 0.81933664, 0.83099501, 0.84157148, 0.85132464,\n",
       "       0.86077023, 0.86940036, 0.87776679, 0.88574372, 0.89320844,\n",
       "       0.90046426, 0.90738337, 0.91392246, 0.92033038, 0.92624422,\n",
       "       0.93195585, 0.93719222, 0.94201029, 0.94654748, 0.95077911,\n",
       "       0.95483964, 0.95881049, 0.96237542, 0.9657833 , 0.96906165,\n",
       "       0.97217197, 0.97505772, 0.97782262, 0.98041436, 0.98275919,\n",
       "       0.98494176, 0.98697774, 0.98893286, 0.99076605, 0.99244551,\n",
       "       0.99405787, 0.9955355 , 0.99688668, 0.99813769, 0.99917465,\n",
       "       1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution here...\n",
    "\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Based on the results from **Exercise 3**, determine how many components are needed to capture at least 85% of the total variance.\n",
    "\n",
    "Discuss the impact of this on subsequent analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio\n",
    "for i, ev in enumerate(explained_variance_ratio):\n",
    "    print(f\"PC{i+1}: Explained Variance = {ev:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explained variance ratios show that the first few principal components (PC1, PC2, PC3) capture the most variance, with PC1 accounting for 12.03%. As we move to higher components, the explained variance decreases, indicating they carry less information about the dataset's overall variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative variance ratio\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Print the cumulative variance ratio\n",
    "for i, cv in enumerate(cumulative_variance_ratio):\n",
    "    print(f\"PC{i+1}: Cumulative Variance = {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that each additional principal component captures more variance. For example, PC1 captures 12.03%, and by PC10, 58.87% is captured. All 64 components capture 100% variance. This helps identify how many components are needed to capture a significant portion of the dataset's variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative variance ratio shows that to reach at least 85% cumulative variance, 25 components are needed.\n",
    "\n",
    "We observe that by retaining the first 25 components, we can capture 85.13% of the total variance in the dataset, which significantly reduces the dataset's dimensionality while retaining most of its information.\n",
    "\n",
    "Using 25 components instead of the original 64 simplifies any downstream models by reducing their feature space, potentially improving model performance and interpretability.\n",
    "\n",
    "The reduced number of components also makes visualising the data easier, which can provide meaningful insights into class separations or clustering.\n",
    "\n",
    "Therefore, the ability to capture over 85% of the variance with 25 components makes PCA a viable dimensionality reduction technique for this dataset, preserving most information while simplifying further analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZFCZhaikX+N2/Bg7W6SY+",
   "collapsed_sections": [],
   "name": "Search_algorithms.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "6b5ebbc2c6bde2831bc6c0426f75aca8137ccfc69d329557556ed73faee126ae"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
